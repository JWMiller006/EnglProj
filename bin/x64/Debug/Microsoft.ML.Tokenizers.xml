<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.ML.Tokenizers</name>
    </assembly>
    <members>
        <member name="T:Microsoft.ML.Tokenizers.EncodingResult">
            <summary>
            The Encoding represents the output of a Tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EncodingResult.#ctor(System.String,System.String,System.Collections.Generic.IEnumerable{Microsoft.ML.Tokenizers.Split},System.Boolean)">
            <summary>
            Create a new object of the EncodingResult object.
            </summary>
            <param name="originalString">The list of tokens to merge.</param>
            <param name="normalizedString">The list of tokens to merge.</param>
            <param name="splits">The list of tokens to merge.</param>
            <param name="offsetsMappedToOriginalString">Indicate whether the offsets is mapped to the original string or the normalized string.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.OriginalString">
            <summary>
            Gets the original tokenized string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.NormalizedString">
            <summary>
            Gets the normalized form of the original string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.OffsetsMappedToOriginalString">
            <summary>
            Gets the normalized form of the original string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.Ids">
            <summary>
            Gets list of the tokens Ids.
            The Ids are the main input to a Language Model. They are the token indices, the numerical representations that a LM understands.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.Tokens">
            <summary>
            Gets the generated tokens. They are the string representation of the Ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodingResult.Offsets">
            <summary>
            Gets The list of offsets. These offsets let's you slice the input string, and thus retrieve
            the original part that led to producing the corresponding token.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Bpe">
            <summary>
            Represent the Byte Pair Encoding model.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.Bpe.MaxWordLengthToCache">
            A [Byte Pair Encoding](https://www.aclweb.org/anthology/P16-1162/) model.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.UnknownToken">
            <summary>
            Gets or Sets unknown token. The unknown token to be used when we encounter an unknown char
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.ContinuingSubwordPrefix">
            <summary>
            A prefix to be used for every subword that is not a beginning-of-word
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.EndOfWordSuffix">
            <summary>
            An optional suffix to characterize and end-of-word sub-word
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.FuseUnknownTokens">
            <summary>
            Gets or sets whether allowing multiple unknown tokens get fused
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.#ctor(System.String,System.String,System.String,System.String,System.String,System.Boolean)">
            <summary>
            Construct a new Bpe model object to use for text encoding.
            </summary>
            <param name="vocabFile">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergesFile">The file path containing the tokens's pairs list.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.#ctor(System.IO.Stream,System.IO.Stream,System.String,System.String,System.String,System.Boolean)">
            <summary>
            Construct a new Bpe model object to use for text encoding.
            </summary>
            <param name="vocabStream">The JSON stream containing the dictionary of string keys and their ids.</param>
            <param name="mergesStream">The stream containing the tokens's pairs list.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.Decoder">
            <summary>
            Gets the Bpe decoder object.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.Encode(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode a text string to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a split text string to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the token.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.Vocab">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.ReadModelData(System.IO.Stream,System.IO.Stream)">
            Read the given files to extract the vocab and merges
        </member>
        <member name="F:Microsoft.ML.Tokenizers.Bpe._vocab">
            The vocabulary assigns a number to each token.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.Merges">
            Contains the mapping between Pairs and their (rank, newId).
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.Cache">
            Contains the cache for optimizing the encoding step.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.VocabReverse">
            Reversed vocabulary, to rebuild the text.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Bpe.Dropout">
            Dropout probability for merges. 0 = no dropout is the default. At 1.0, tokenization will
            perform no merges, so the result will just be characters.
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Bpe.ConvertMergesToHashmap(System.IO.Stream)">
            Converts the merges strings (for example from `merges.txt` file) with the format
            "{pair_a} {pair_b}" into the format expected by the BPE struct
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BpeDecoder">
            <summary>
            Allows decoding Original BPE by joining all the tokens and then replacing
            the suffix used to identify end-of-words by white spaces
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeDecoder.#ctor">
            <summary>
            Construct a new Bpe decoder object.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeDecoder.#ctor(System.String)">
            <summary>
            Construct a new Bpe decoder object.
            </summary>
            <param name="suffix">The suffix that was used to characterize an end-of-word. This suffix will be replaced by white spaces during the decoding.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeDecoder.Decode(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Decode the original BPE by joining all the tokens and then replacing the suffix used to identify end-of-words by white spaces.
            </summary>
            <param name="tokens">The list of tokens to merge.</param>
            <returns>The string containing all merged tokens.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.EnglishRoberta">
            <summary>
            Represent the Byte Pair Encoding model.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRoberta.FilterUnsupportedChars">
            <summary>
            Indicate if want to filter the unsupported characters during the decoding.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.#ctor(System.String,System.String,System.String,System.Boolean)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingPath">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.#ctor(System.IO.Stream,System.IO.Stream,System.IO.Stream,System.Boolean)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingStream">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRoberta.Vocab">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the string.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.Encode(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode a text string to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a split text string to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.ConvertIdsToOccurrenceRanks(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of tokens Ids to highest occurrence rankings.
            </summary>
            <param name="ids">The Ids list to map to the high occurrence rank.</param>
            <returns>The list of ranks mapped from the list of Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.ConvertIdsToOccurrenceValues(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of tokens Ids to highest occurrence values.
            </summary>
            <param name="ids">The Ids list to map to the high occurrence values.</param>
            <returns>The list of occurrence values mapped from the list of Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.ConvertOccurrenceRanksToIds(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of highest occurrence rankings to tokens Ids list .
            </summary>
            <param name="ranks">The high occurrence ranks list to map to the Ids list.</param>
            <returns>The list of Ids mapped from the list of ranks.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRoberta.PadIndex">
            <summary>
            Gets the index of the pad symbol inside the symbols list.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRoberta.SymbolsCount">
            <summary>
            Gets the symbols list length.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.AddMaskSymbol(System.String)">
            <summary>
            Add the mask symbol to the symbols list.
            </summary>
            <param name="mask">The mask symbol.</param>
            <returns>The index of the mask symbol in the symbols list.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.GetByteToUnicode(System.Collections.Generic.IReadOnlyDictionary{System.Char,System.Char}@)">
            <summary>
            Returns list of utf-8 bytes and a corresponding list of unicode chars.
            This mapping is to make unseen characters (such as control characters) displayable.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.EncodeToTokens(System.Span{System.Char},System.Span{System.Int32})">
            <summary>
            Encode a token into BPE-ed sub-tokens. E.g., "playing" into ["play", "ing"].
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.WordToPairs(System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.HashSet{System.ValueTuple{System.String,System.String}})">
            <summary>
            Extract element pairs in an aggregating word. E.g. [p, l, ay] into [(p,l), (l,ay)].
            If word contains 0 or 1 element, an empty HashSet will be returned.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRoberta.IsSupportedChar(System.Char)">
            <summary>
            Check if the character is supported by the tokenizer's model.
            </summary>
            <param name="ch">The character to check.</param>
            <returns>True if the character is supported, otherwise false.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.HighestOccurrenceMapping">
            <summary>
            HighestOccurrenceMapping maps the GPT-2 vocabulary Id to highest occurrence value came from dict.txt file
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.#ctor(System.String,System.String,System.String,System.String,System.String[])">
            <exception cref="T:System.ArgumentNullException">Any of `pad`, `eos`, `unk` and `bos` is `null`.</exception>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.Item(System.Int32)">
            <exception cref="T:System.ArgumentOutOfRangeException">`idx` is negative.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.IndexOf(System.Int32)">
            <exception cref="T:System.ArgumentNullException">`symbol` is `null`.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.Load(System.IO.Stream)">
            <summary>
            Loads the mapping from a text file with the format:
                13 850314647
                262 800385005
                11 800251374
                284 432911125
                ...
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.AddFromStream(System.IO.Stream)">
            <summary>
            Loads a pre-existing vocabulary from a text stream and adds its symbols to this instance.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Model">
            <summary>
            Represents a model used during Tokenization (like BPE or Word Piece or Unigram).
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.Encode(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode a text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a text to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode. </param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>
            This method does the default implementation that uses the Encode method to get the token's Ids.
            Tokenizer's models which care about performance may choose to override this method to provide a more efficient implementation.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>
            This method does the default implementation that uses the EncodeToIds method to get the number of token's Ids.
            Tokenizer's models which care about performance may choose to override this method to provide a more efficient implementation.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>
            This method does the default implementation that uses the EncodeToIds method to get the number of token's Ids.
            Tokenizer's models which care about performance may choose to override this method to provide a more efficient implementation.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded id with the option to skip the special tokens.
            </summary>
            <param name="token">The token to map to Id</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the token.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Model.Decode(System.Collections.Generic.IEnumerable{System.Int32},Microsoft.ML.Tokenizers.TokenizerDecoder)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="decoder">The optional Decoder to merge the given list of tokens in a string.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePieceBpe">
            <summary>
            SentencePieceBpe is a tokenizer that splits the input into tokens using the SentencePiece Bpe model.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.ByteFallback">
            <summary>
            Specifies whether the model will do a byte fallback when it encounters unknown tokens during the encoding process.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.AddDummyPrefix">
            <summary>
            Indicate emitting the prefix character U+2581 at the beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.EscapeWhiteSpaces">
            <summary>
            Indicate if the spaces should be replaced with character U+2581 during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.TreatWhitespaceAsSuffix">
            <summary>
            Indicate emitting the character U+2581 at the end of the last sentence token instead beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.AddBeginningOfSentence">
            <summary>
            Indicate emitting the beginning of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.AddEndOfSentence">
            <summary>
            Indicate emitting the end of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.BeginningOfSentenceToken">
            <summary>
            The beginning of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.EndOfSentenceToken">
            <summary>
            The end of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.UnknownToken">
            <summary>
            The unknown token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.BeginningOfSentenceId">
            <summary>
            The id of the beginning of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.EndOfSentenceId">
            <summary>
            The id of the end of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.UnknownId">
            <summary>
            The id of the unknown token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceBpe.Vocab">
            <summary>
            The vocabulary of the model.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.Encode(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode a text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.Encode(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean)">
            <summary>
            Encode a text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a text to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a text to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded id with the option to skip the special tokens.
            </summary>
            <param name="token">The token to map to Id</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the token.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpe.Decode(System.Collections.Generic.IEnumerable{System.Int32},Microsoft.ML.Tokenizers.TokenizerDecoder)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="decoder">The optional Decoder to merge the given list of tokens in a string.</param>
            <returns>The decoded string.</returns>
            <remarks>
            The decoder is not used here because the SentencePiece Bpe model knows how to decode the ids in additions to avoid any performance overhead.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Symbol.MergeWith(Microsoft.ML.Tokenizers.Symbol@,System.Int32)">
            Merges the current Symbol with the other one.
            In order to update prev/next, we consider Self to be the Symbol on the left,
            and other to be the next one on the right.
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Tiktoken">
            <summary>
            Represent the rapid Byte Pair Encoding model commonly referred to as Tiktoken.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.#ctor(System.String,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's model object.
            </summary>
            <param name="vocabFilePath">The path to the BPE vocab file.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when <paramref name="vocabFilePath"/> is null or empty.</exception>
            <exception cref="T:System.InvalidOperationException">Thrown when failed to load the BPE vocab file.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.#ctor(System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's model object.
            </summary>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when <paramref name="vocabStream"/> is null or empty.</exception>
            <exception cref="T:System.InvalidOperationException">Thrown when failed to load the BPE vocab file.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.#ctor(System.Collections.Generic.Dictionary{System.ReadOnlyMemory{System.Byte},System.Int32},System.Collections.Generic.Dictionary{System.Int32,System.ReadOnlyMemory{System.Byte}},System.Collections.Generic.Dictionary{Microsoft.ML.Tokenizers.StringSpanOrdinalKey,System.ValueTuple{System.Int32,System.String}},System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's model object.
            </summary>
            <param name="encoder">The dictionary mapping token utf-8 bytes to Ids.</param>
            <param name="decoder">The dictionary mapping Ids to token utf-8 bytes.</param>
            <param name="vocab">The dictionary mapping string tokens to Ids.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The max size of the cache to use.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.CreateAsync(System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,System.Threading.CancellationToken)">
            <summary>
            Create a new Tiktoken tokenizer's model object asynchronously.
            </summary>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>Tiktoken tokenizer's object.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.CreateAsync(System.String,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,System.Threading.CancellationToken)">
            <summary>
            Create a new Tiktoken tokenizer's object asynchronously.
            </summary>
            <param name="vocabFilePath">The BPE vocab file.</param>
            <param name="specialTokensEncoder">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>Tiktoken tokenizer's model object.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.LoadTiktokenBpeAsync(System.IO.Stream,System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Load BPE vocab dictionary from a stream.
            </summary>
            <param name="vocabStream">Stream to the BPE vocab file</param>
            <param name="useAsync">Whether to perform I/O synchronously or asynchronously.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>Map of byte[] to integer token id</returns>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.Encode(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode text to a list of Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated Ids.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textLength">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the token.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tiktoken.Decode(System.Collections.Generic.IEnumerable{System.Int32},Microsoft.ML.Tokenizers.TokenizerDecoder)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="decoder">The optional Decoder to merge the given list of tokens in a string.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tiktoken.Vocab">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
            <remarks>This may not contain the full set of vocabulary tokens, use Encoder to get the full set of vocabulary.</remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tiktoken.SpecialTokens">
            <summary>
            Gets the dictionary mapping special tokens to Ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tiktoken.Encoder">
            <summary>
            Gets the dictionary mapping token bytes to Ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tiktoken.Decoder">
            <summary>
            Gets the dictionary mapping Ids to token utf-8 bytes.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.LlamaNormalizer">
            <summary>
            Normalize the string to lowercase form before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LlamaNormalizer.#ctor(System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Creates a LowerCaseNormalizer object.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.LlamaNormalizer.RemoveExtraWhiteSpaces">
            <summary>
            Indicate removing extra white spaces from the original string during the normalization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.LlamaNormalizer.AddDummyPrefix">
            <summary>
            Indicate emitting the dummy prefix character U+2581 at the beginning of sentence token during the encoding.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LlamaNormalizer.Normalize(System.String)">
            <summary>
            Normalize the original string according to SentencePiece normalization with Llama model.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.LowerCaseNormalizer">
            <summary>
            Normalize the string to lowercase form before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LowerCaseNormalizer.#ctor">
            <summary>
            Creates a LowerCaseNormalizer object.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LowerCaseNormalizer.Normalize(System.String)">
            <summary>
            Lowercase the original string.
            </summary>
            <param name="original">The original string to normalize to lowercase form.</param>
            <returns>The lower-cased normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Normalizer">
            <summary>
            Normalize the string before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Normalizer.Normalize(System.String)">
            <summary>
            Process the original string to modify it and obtain a normalized string.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.UpperCaseNormalizer">
            <summary>
            Normalize the string to uppercase form before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.UpperCaseNormalizer.#ctor">
            <summary>
            Creates a UpperCaseNormalizer object.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.UpperCaseNormalizer.Normalize(System.String)">
            <summary>
            Uppercase the original string.
            </summary>
            <param name="original">The original string to normalize to uppercase form.</param>
            <returns>The upper-cased normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Split">
            <summary>
            This Split contains the underlying split token as well as its offsets
            in the original string. These offsets are in the `original` referential.
            It also contains any `Token` associated to the current split.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Split.TokenString">
            <summary>
            Gets the underlying split token. Each SubString is represented by a token
            and in the end we might be carrying a lot of SubString representing various parts of the
            original input string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Split.TokenSpan">
            <summary>
            Gets the underlying split token as a span.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Split.Offset">
            <summary>
            Returns the offset mapping to the original string
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Split.#ctor(System.String,System.ValueTuple{System.Int32,System.Int32})">
            <summary>
            create a Split object using the token and the offset
            </summary>
            <param name="token">The token string</param>
            <param name="offset">The offset mapping to the original string</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Split.Equals(Microsoft.ML.Tokenizers.Split)">
            <summary>
            Indicates whether the current Split object is equal to another Split object.
            </summary>
            <param name="other">The Split object to compare with the current object.</param>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.PreTokenizer">
            <summary>
            Base class for all pre-tokenizers classes.
            The PreTokenizer is in charge of doing the pre-segmentation step.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.PreTokenize(System.String)">
            <summary>
            Splits the given string in multiple substrings at the word boundary, keeping track of the offsets of said substrings from the original string.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The list of the splits containing the tokens and the token's offsets to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.RobertaPreTokenizer">
            <summary>
            The pre-tokenizer for Roberta English tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.RobertaPreTokenizer.Instance">
            <summary>
            Gets a singleton instance of the Roberta pre-tokenizer..
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RobertaPreTokenizer.PreTokenize(System.String)">
            <summary>
            Splits the given string in multiple substrings at the word boundary, keeping track of the offsets of said substrings from the original string.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The list of the splits containing the tokens and the token's offsets to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePiecePreTokenizer">
            <summary>
            The pre-tokenizer for SentencePiece tokenizers.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePiecePreTokenizer.Instance">
            <summary>
            Gets a singleton instance of the Roberta pre-tokenizer..
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePiecePreTokenizer.PreTokenize(System.String)">
            <summary>
            Return the whole text as one chunk.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The original string as one chunk.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.TiktokenPreTokenizer">
            <summary>
            The pre-tokenizer for Tiktoken tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenPreTokenizer.#ctor(System.Text.RegularExpressions.Regex,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.ML.Tokenizers.TiktokenPreTokenizer"/> class.
            </summary>
            <param name="regex">The regex to use for splitting the text into smaller tokens in the pre-tokenization process.</param>
            <param name="specialTokensEncoder">The dictionary containing the special tokens and their corresponding ids.</param>
            <exception cref="T:System.ArgumentNullException">When regex is null</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenPreTokenizer.PreTokenize(System.String)">
            <summary>
            Splits the given string in multiple substrings at the word boundary, keeping track of the offsets of said substrings from the original string.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The list of the splits containing the tokens and the token's offsets to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.WhiteSpace">
            <summary>
            The pre-tokenizer which split the text at the word boundary.
            The word is a set of alphabet, numeric, and underscore characters.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WhiteSpace.Instance">
            <summary>
            Gets a singleton instance of the WhiteSpace pre-tokenizer..
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WhiteSpace.PreTokenize(System.String)">
            <summary>
            Splits the given string in multiple substrings at the word boundary, keeping track of the offsets of said substrings from the original string.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The list of the splits containing the tokens and the token's offsets to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Token">
            <summary>
            Represent the token produced from the tokenization process containing the token substring,
            the id associated to the token substring, and the offset mapping to the original string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Token.Id">
            <summary>
            Gets the Id value associated to the token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Token.Value">
            <summary>
            Gets the token string value.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Token.Offset">
            <summary>
            Gets the offset mapping to the original string.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Token.#ctor(System.Int32,System.String,System.ValueTuple{System.Int32,System.Int32})">
            <summary>
            Construct a new Token object using the token value, Id, and the offset mapping to the original string.
            </summary>
            <param name="id">The Id value associated to the token.</param>
            <param name="value">The token string value.</param>
            <param name="offset">The offset mapping to the original string.</param>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Tokenizer">
            <summary>
            A Tokenizer works as a pipeline. It processes some raw text as input and outputs a EncodingResult object.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.#ctor(Microsoft.ML.Tokenizers.Model,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,Microsoft.ML.Tokenizers.TokenizerDecoder)">
            <summary>
            Create a new Tokenizer object.
            </summary>
            <param name="model">The Model in use by the Tokenizer.</param>
            <param name="preTokenizer">The optional PreTokenizer in use by the Tokenizer. WhiteSpace PreTokenizer will be used if this parameter is null.</param>
            <param name="normalizer">The optional Normalizer in use by the Tokenizer.</param>
            <param name="decoder">The optional Decoder in use by the Tokenizer during the decoding operation to merge the given list of tokens in a string.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.Model">
            <summary>
            Gets the Model in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.PreTokenizer">
            <summary>
            Gets or sets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.Normalizer">
            <summary>
            Gets or sets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.Decoder">
            <summary>
            Gets or sets the Decoder in use by the Tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.Encode(System.String)">
            <summary>
            Encodes input text to object has the tokens list, tokens Ids, tokens offset mapping.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The tokenization result includes the tokens list, tokens Ids, tokens offset mapping.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.String)">
            <summary>
            Encodes input text to tokens Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The tokenization result includes the tokens list, tokens Ids, tokens offset mapping.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CountTokens(System.String)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The number of tokens Ids that the input text will be encoded to.</returns>
            <exception cref="T:System.ArgumentNullException">The input text is null.</exception>
            <exception cref="T:System.ArgumentException">Unable to encode the text.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.IndexOfTokenCount(System.String,System.Int32,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity from the start within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="processedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will remain unchanged as the input text.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely, if all tokens fit, the result will be length of the <paramref name="processedText"/>.
            </returns>
            <exception cref="T:System.ArgumentNullException">The input text is null.</exception>
            <exception cref="T:System.ArgumentOutOfRangeException">The maximum token count must be greater than 0.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.LastIndexOfTokenCount(System.String,System.Int32,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity from the end within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="processedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will remain unchanged as the input text.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The start index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index at the first character to be included. In cases where no tokens fit, the result will be length of the <paramref name="processedText"/>; conversely, if all tokens fit, the result will be 0.
            </returns>
            <exception cref="T:System.ArgumentNullException">The input text is null.</exception>
            <exception cref="T:System.ArgumentOutOfRangeException">The maximum token count must be greater than 0.</exception>
            <remarks>
            If the whole text can be encoded within the token limit, the returned index will be 0.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.Decode(System.Int32)">
            <summary>
            Decodes the Id to the mapped token.
            </summary>
            <param name="id">The id to map to the token.</param>
            <returns>The decoded string or null if there is no token mapped to the input id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CreateTiktokenForModel(System.String,System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,Microsoft.ML.Tokenizers.Normalizer)">
            <summary>
            Create a Tiktoken tokenizer based on model name and vocab file.
            </summary>
            <param name="modelName">Model name</param>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CreateTiktokenForModelAsync(System.String,System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,Microsoft.ML.Tokenizers.Normalizer,System.Threading.CancellationToken)">
            <summary>
            Create a Tiktoken tokenizer based on model name and vocab file.
            </summary>
            <param name="modelName">Model name</param>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CreateTiktokenForModel(System.String,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer)">
            <summary>
            Create tokenizer based on model name
            </summary>
            <param name="modelName">Model name</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CreateLlama(System.IO.Stream,System.Boolean,System.Boolean)">
            <summary>
            Create a SentencePieceBpe tokenizer from the given model stream. The model stream should contain the SentencePiece Bpe model according to
            https://github.com/google/sentencepiece/blob/master/src/sentencepiece_model.proto specification.
            </summary>
            <param name="modelStream">The stream containing the SentencePiece Bpe model.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.TokenizerDecoder">
            <summary>
            A Decoder has the responsibility to merge the given list of tokens in a string.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TokenizerDecoder.Decode(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Decode by joining all the tokens to a string.
            </summary>
            <param name="tokens">The list of tokens to merge.</param>
            <returns>The string containing all merged tokens.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BytePairEncoder">
            <summary>
            This class implements the byte pair encoding algorithm.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.LruCache`1.DefaultCacheSize">
            <summary>
            The default LRU cache size.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.#ctor(System.Int32)">
            <summary>
            Constructs an <see cref="T:Microsoft.ML.Tokenizers.LruCache`1" /> object.
            </summary>
            <param name="cacheSize">
            The maximum number of mappings that can be cached. This defaults to <see cref="F:Microsoft.ML.Tokenizers.LruCache`1.DefaultCacheSize" />, which is set to <value>8192</value>.
            </param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.TryGetValue(System.String,`0@)">
            <summary>
            Retrieves the value associated with the specified key /> object.
            </summary>
            <param name="key">The object to be used as a key.</param>
            <param name="value">An out parameter that is set to the value of the key if key contains a mapping in the cache.</param>
            <returns>
            true if the cache contains a mapping for key, false otherwise.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.TryGetValue(System.ReadOnlySpan{System.Char},`0@)">
            <summary>
            Retrieves the value associated with the specified key /> object.
            </summary>
            <param name="key">The object to be used as a key.</param>
            <param name="value">An out parameter that is set to the value of the key if key contains a mapping in the cache.</param>
            <returns>
            true if the cache contains a mapping for key, false otherwise.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.Add(System.String,`0)">
            <summary>
            Adds or replaces a mapping in the cache.
            </summary>
            <param name="key">The key whose mapped <paramref name="value" /> is to be created or replaced.</param>
            <param name="value">The new value to be mapped to the <paramref name="key" />.</param>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey">
            <summary>Used as a key in a dictionary to enable querying with either a string or a span.</summary>
            <remarks>
            This should only be used with a Ptr/Length for querying. For storing in a dictionary, this should
            always be used with a string.
            </remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKeyConverter">
            <summary>
            Custom JSON converter for <see cref="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey"/>.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKeyExtensions">
            <summary>
            Extension methods for <see cref="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey"/>.
            </summary>
        </member>
        <member name="T:Sentencepiece.SentencepieceModelReflection">
            <summary>Holder for reflection information generated from sentencepiece_model.proto</summary>
        </member>
        <member name="P:Sentencepiece.SentencepieceModelReflection.Descriptor">
            <summary>File descriptor for sentencepiece_model.proto</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec">
            <summary>
            TrainerSpec encodes a various parameters for SentencePiece training.
            Next id: 55
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.Input" -->
        <member name="F:Sentencepiece.TrainerSpec.InputFormatFieldNumber">
            <summary>Field number for the "input_format" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.InputFormat">
            <summary>
            Input corpus format:
            "text": one-sentence-per-line text format (default)
            "tsv":  sentence &lt;tab> freq
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasInputFormat">
            <summary>Gets whether the "input_format" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearInputFormat">
            <summary>Clears the value of the "input_format" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ModelPrefixFieldNumber">
            <summary>Field number for the "model_prefix" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ModelPrefix">
            <summary>
            Output model file prefix.
            &lt;model_prefix>.model and &lt;model_prefix>.vocab are generated.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasModelPrefix">
            <summary>Gets whether the "model_prefix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearModelPrefix">
            <summary>Clears the value of the "model_prefix" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ModelTypeFieldNumber">
            <summary>Field number for the "model_type" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasModelType">
            <summary>Gets whether the "model_type" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearModelType">
            <summary>Clears the value of the "model_type" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.VocabSizeFieldNumber">
            <summary>Field number for the "vocab_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.VocabSize">
            <summary>
            Vocabulary size. 8k is the default size.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasVocabSize">
            <summary>Gets whether the "vocab_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearVocabSize">
            <summary>Clears the value of the "vocab_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.AcceptLanguageFieldNumber">
            <summary>Field number for the "accept_language" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.AcceptLanguage">
            <summary>
            List of the languages this model can accept.
            Since the model is language-agnostic, this field is used as a reference.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SelfTestSampleSizeFieldNumber">
            <summary>Field number for the "self_test_sample_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SelfTestSampleSize">
            <summary>
            Size of self-test samples, which are encoded in the model file.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSelfTestSampleSize">
            <summary>Gets whether the "self_test_sample_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSelfTestSampleSize">
            <summary>Clears the value of the "self_test_sample_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EnableDifferentialPrivacyFieldNumber">
            <summary>Field number for the "enable_differential_privacy" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.EnableDifferentialPrivacy">
            <summary>
            Whether to use DP version of sentencepiece. Use it with TSV input format
            (requires precomputed word tab counts to work).
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEnableDifferentialPrivacy">
            <summary>Gets whether the "enable_differential_privacy" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEnableDifferentialPrivacy">
            <summary>Clears the value of the "enable_differential_privacy" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.DifferentialPrivacyNoiseLevelFieldNumber">
            <summary>Field number for the "differential_privacy_noise_level" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.DifferentialPrivacyNoiseLevel">
            <summary>
            Set these parameters if you need DP version of sentencepiece.
            std of noise to add.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasDifferentialPrivacyNoiseLevel">
            <summary>Gets whether the "differential_privacy_noise_level" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearDifferentialPrivacyNoiseLevel">
            <summary>Clears the value of the "differential_privacy_noise_level" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.DifferentialPrivacyClippingThresholdFieldNumber">
            <summary>Field number for the "differential_privacy_clipping_threshold" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.DifferentialPrivacyClippingThreshold">
            <summary>
            Clipping threshold to apply after adding noise. All the words with
            frequency less than this value are dropped.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasDifferentialPrivacyClippingThreshold">
            <summary>Gets whether the "differential_privacy_clipping_threshold" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearDifferentialPrivacyClippingThreshold">
            <summary>Clears the value of the "differential_privacy_clipping_threshold" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.CharacterCoverageFieldNumber">
            <summary>Field number for the "character_coverage" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.CharacterCoverage" -->
        <member name="P:Sentencepiece.TrainerSpec.HasCharacterCoverage">
            <summary>Gets whether the "character_coverage" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearCharacterCoverage">
            <summary>Clears the value of the "character_coverage" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.InputSentenceSizeFieldNumber">
            <summary>Field number for the "input_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.InputSentenceSize">
            <summary>
            Maximum size of sentences the trainer loads from `input` parameter.
            Trainer simply loads the `input` files in sequence.
            It is better to shuffle the input corpus randomly.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasInputSentenceSize">
            <summary>Gets whether the "input_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearInputSentenceSize">
            <summary>Clears the value of the "input_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ShuffleInputSentenceFieldNumber">
            <summary>Field number for the "shuffle_input_sentence" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasShuffleInputSentence">
            <summary>Gets whether the "shuffle_input_sentence" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearShuffleInputSentence">
            <summary>Clears the value of the "shuffle_input_sentence" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MiningSentenceSizeFieldNumber">
            <summary>Field number for the "mining_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.MiningSentenceSize">
            <summary>
            Maximum size of sentences to make seed sentence pieces.
            Extended suffix array is constructed to extract frequent
            sub-strings from the corpus. This uses 20N working space,
            where N is the size of corpus.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasMiningSentenceSize">
            <summary>Gets whether the "mining_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMiningSentenceSize">
            <summary>Clears the value of the "mining_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TrainingSentenceSizeFieldNumber">
            <summary>Field number for the "training_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TrainingSentenceSize">
            <summary>
            Maximum size of sentences to train sentence pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTrainingSentenceSize">
            <summary>Gets whether the "training_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTrainingSentenceSize">
            <summary>Clears the value of the "training_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SeedSentencepieceSizeFieldNumber">
            <summary>Field number for the "seed_sentencepiece_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SeedSentencepieceSize">
            <summary>
            The size of seed sentencepieces.
            `seed_sentencepiece_size` must be larger than `vocab_size`.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSeedSentencepieceSize">
            <summary>Gets whether the "seed_sentencepiece_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSeedSentencepieceSize">
            <summary>Clears the value of the "seed_sentencepiece_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ShrinkingFactorFieldNumber">
            <summary>Field number for the "shrinking_factor" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ShrinkingFactor">
            <summary>
            In every EM sub-iterations, keeps top
            `shrinking_factor` * `current sentencepieces size` with respect to
            the loss of the sentence piece. This value should be smaller than 1.0.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasShrinkingFactor">
            <summary>Gets whether the "shrinking_factor" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearShrinkingFactor">
            <summary>Clears the value of the "shrinking_factor" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MaxSentenceLengthFieldNumber">
            <summary>Field number for the "max_sentence_length" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.MaxSentenceLength">
            <summary>
            The maximum sentence length in byte. The sentences with the length
            larger than `max_sentence_length` is simply ignored.
            Longer input tends to bring the following risks:
             * Overflow during EM training (unigram language model only)
             * Performance drop because of O(n log n) cost in BPE.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasMaxSentenceLength">
            <summary>Gets whether the "max_sentence_length" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMaxSentenceLength">
            <summary>Clears the value of the "max_sentence_length" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.NumThreadsFieldNumber">
            <summary>Field number for the "num_threads" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.NumThreads">
            <summary>
            Number of threads in the training.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasNumThreads">
            <summary>Gets whether the "num_threads" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearNumThreads">
            <summary>Clears the value of the "num_threads" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.NumSubIterationsFieldNumber">
            <summary>Field number for the "num_sub_iterations" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.NumSubIterations">
            <summary>
            Number of EM sub iterations.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasNumSubIterations">
            <summary>Gets whether the "num_sub_iterations" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearNumSubIterations">
            <summary>Clears the value of the "num_sub_iterations" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MaxSentencepieceLengthFieldNumber">
            <summary>Field number for the "max_sentencepiece_length" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.MaxSentencepieceLength" -->
        <member name="P:Sentencepiece.TrainerSpec.HasMaxSentencepieceLength">
            <summary>Gets whether the "max_sentencepiece_length" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMaxSentencepieceLength">
            <summary>Clears the value of the "max_sentencepiece_length" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByUnicodeScriptFieldNumber">
            <summary>Field number for the "split_by_unicode_script" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByUnicodeScript">
            <summary>
            Uses Unicode script to split sentence pieces.
            When `split_by_unicode_script` is true, we do not allow sentence piece to
            include multiple Unicode scripts, e.g. "F1" is not a valid piece.
            Exception: CJ characters (Hiragana/Katakana/Han) are all handled
            as one script type, since Japanese word can consist of multiple scripts.
            This exception is always applied regardless of the accept-language
            parameter.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByUnicodeScript">
            <summary>Gets whether the "split_by_unicode_script" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByUnicodeScript">
            <summary>Clears the value of the "split_by_unicode_script" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByNumberFieldNumber">
            <summary>Field number for the "split_by_number" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByNumber">
            <summary>
            When `split_by_number` is true, put a boundary between number and
            non-number transition. If we want to treat "F1" is one token, set this flag
            to be false.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByNumber">
            <summary>Gets whether the "split_by_number" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByNumber">
            <summary>Clears the value of the "split_by_number" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByWhitespaceFieldNumber">
            <summary>Field number for the "split_by_whitespace" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByWhitespace">
            <summary>
            Use a white space to split sentence pieces.
            When `split_by_whitespace` is false, we may have the piece containing
            a white space in the middle. e.g., "in_the".
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByWhitespace">
            <summary>Gets whether the "split_by_whitespace" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByWhitespace">
            <summary>Clears the value of the "split_by_whitespace" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TreatWhitespaceAsSuffixFieldNumber">
            <summary>Field number for the "treat_whitespace_as_suffix" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TreatWhitespaceAsSuffix">
            <summary>
            Adds whitespace symbol (_) as a suffix instead of prefix. e.g., _hello =>
            hello_. When `treat_whitespace_as_suffix` is true,
            NormalizerSpec::add_dummy_prefix will add the dummy whitespace to the end
            of sentence.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTreatWhitespaceAsSuffix">
            <summary>Gets whether the "treat_whitespace_as_suffix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTreatWhitespaceAsSuffix">
            <summary>Clears the value of the "treat_whitespace_as_suffix" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.AllowWhitespaceOnlyPiecesFieldNumber">
            <summary>Field number for the "allow_whitespace_only_pieces" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.AllowWhitespaceOnlyPieces">
            <summary>
            Allows pieces that only contain whitespaces instead of appearing only as
            prefix or suffix of other pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasAllowWhitespaceOnlyPieces">
            <summary>Gets whether the "allow_whitespace_only_pieces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearAllowWhitespaceOnlyPieces">
            <summary>Clears the value of the "allow_whitespace_only_pieces" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitDigitsFieldNumber">
            <summary>Field number for the "split_digits" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitDigits">
            <summary>
            Split all digits (0-9) into separate pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitDigits">
            <summary>Gets whether the "split_digits" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitDigits">
            <summary>Clears the value of the "split_digits" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PretokenizationDelimiterFieldNumber">
            <summary>Field number for the "pretokenization_delimiter" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.PretokenizationDelimiter">
            <summary>
            Defines the pre-tokenization delimiter.
            When specified, no pieces crossing this delimiter is not included
            in the vocab. Then the delimiter string is virtually ignored
            during the training. This field can allows constraints on the vocabulary
            selection. Note that this field is available on unigram mode.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPretokenizationDelimiter">
            <summary>Gets whether the "pretokenization_delimiter" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPretokenizationDelimiter">
            <summary>Clears the value of the "pretokenization_delimiter" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ControlSymbolsFieldNumber">
            <summary>Field number for the "control_symbols" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.ControlSymbols" -->
        <member name="F:Sentencepiece.TrainerSpec.UserDefinedSymbolsFieldNumber">
            <summary>Field number for the "user_defined_symbols" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UserDefinedSymbols">
            <summary>
            Defines user defined symbols.
            These symbols are added with extremely high score
            so they are always treated as one unique symbol in any context.
            Typical usage of user_defined_symbols is placeholder for named entities.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.RequiredCharsFieldNumber">
            <summary>Field number for the "required_chars" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.RequiredChars">
            <summary>
            Defines required characters. Each UTF8 character in this string is included
            in the character set regardless of character_coverage value. Unlike
            user_defined_symbols, these characters have scores based on the frequency
            on input sentences, and the model can form subwords using characters
            in this field.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasRequiredChars">
            <summary>Gets whether the "required_chars" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearRequiredChars">
            <summary>Clears the value of the "required_chars" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ByteFallbackFieldNumber">
            <summary>Field number for the "byte_fallback" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ByteFallback">
            <summary>
            Decomposes unknown pieces into UTF-8 bytes.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasByteFallback">
            <summary>Gets whether the "byte_fallback" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearByteFallback">
            <summary>Clears the value of the "byte_fallback" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.VocabularyOutputPieceScoreFieldNumber">
            <summary>Field number for the "vocabulary_output_piece_score" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.VocabularyOutputPieceScore">
            <summary>
            When creating the vocabulary file, defines whether or not to additionally
            output the score for each piece.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasVocabularyOutputPieceScore">
            <summary>Gets whether the "vocabulary_output_piece_score" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearVocabularyOutputPieceScore">
            <summary>Clears the value of the "vocabulary_output_piece_score" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.HardVocabLimitFieldNumber">
            <summary>Field number for the "hard_vocab_limit" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HardVocabLimit">
            <summary>
            `vocab_size` is treated as hard limit. Crash if
            the model can not produce the vocab of size `vocab_size`,
            When `hard_vocab_limit` is false, vocab_size is treated
            as soft limit. Note that when model_type=char,
            always assumes hard_vocab_limit = false.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasHardVocabLimit">
            <summary>Gets whether the "hard_vocab_limit" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearHardVocabLimit">
            <summary>Clears the value of the "hard_vocab_limit" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UseAllVocabFieldNumber">
            <summary>Field number for the "use_all_vocab" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UseAllVocab">
            <summary>
            use all symbols for vocab extraction. This flag is valid
            if model type is either CHAR or WORD
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUseAllVocab">
            <summary>Gets whether the "use_all_vocab" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUseAllVocab">
            <summary>Clears the value of the "use_all_vocab" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkIdFieldNumber">
            <summary>Field number for the "unk_id" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.UnkId" -->
        <member name="P:Sentencepiece.TrainerSpec.HasUnkId">
            <summary>Gets whether the "unk_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkId">
            <summary>Clears the value of the "unk_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.BosIdFieldNumber">
            <summary>Field number for the "bos_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.BosId">
            <summary>
            &lt;s>
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasBosId">
            <summary>Gets whether the "bos_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearBosId">
            <summary>Clears the value of the "bos_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EosIdFieldNumber">
            <summary>Field number for the "eos_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.EosId">
            <summary>
            &lt;/s>
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEosId">
            <summary>Gets whether the "eos_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEosId">
            <summary>Clears the value of the "eos_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PadIdFieldNumber">
            <summary>Field number for the "pad_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.PadId">
            <summary>
            &lt;pad> (padding)
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPadId">
            <summary>Gets whether the "pad_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPadId">
            <summary>Clears the value of the "pad_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkPieceFieldNumber">
            <summary>Field number for the "unk_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUnkPiece">
            <summary>Gets whether the "unk_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkPiece">
            <summary>Clears the value of the "unk_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.BosPieceFieldNumber">
            <summary>Field number for the "bos_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasBosPiece">
            <summary>Gets whether the "bos_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearBosPiece">
            <summary>Clears the value of the "bos_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EosPieceFieldNumber">
            <summary>Field number for the "eos_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEosPiece">
            <summary>Gets whether the "eos_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEosPiece">
            <summary>Clears the value of the "eos_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PadPieceFieldNumber">
            <summary>Field number for the "pad_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPadPiece">
            <summary>Gets whether the "pad_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPadPiece">
            <summary>Clears the value of the "pad_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkSurfaceFieldNumber">
            <summary>Field number for the "unk_surface" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UnkSurface">
            <summary>
            Encodes &lt;unk> into U+2047 (DOUBLE QUESTION MARK),
            since this character can be useful both for user and
            developer. We can easily figure out that &lt;unk> is emitted.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUnkSurface">
            <summary>Gets whether the "unk_surface" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkSurface">
            <summary>Clears the value of the "unk_surface" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TrainExtremelyLargeCorpusFieldNumber">
            <summary>Field number for the "train_extremely_large_corpus" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TrainExtremelyLargeCorpus">
            <summary>
            Increase bit depth to allow unigram model training on large
            (>10M sentences) corpora. A Side-effect of enabling this flag
            is increased memory usage.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTrainExtremelyLargeCorpus">
            <summary>Gets whether the "train_extremely_large_corpus" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTrainExtremelyLargeCorpus">
            <summary>Clears the value of the "train_extremely_large_corpus" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SeedSentencepiecesFileFieldNumber">
            <summary>Field number for the "seed_sentencepieces_file" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SeedSentencepiecesFile">
            <summary>
            Path to a seed sentencepieces file, with one tab-separated
            seed sentencepiece &lt;tab> frequency per line.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSeedSentencepiecesFile">
            <summary>Gets whether the "seed_sentencepieces_file" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSeedSentencepiecesFile">
            <summary>Clears the value of the "seed_sentencepieces_file" field</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec.Types">
            <summary>Container for nested types declared in the TrainerSpec message type.</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec.Types.ModelType">
            <summary>
            Model type. only have UNIGRAM now.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Unigram">
            <summary>
            Unigram language model with dynamic algorithm
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Bpe">
            <summary>
            Byte Pair Encoding
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Word">
            <summary>
            Delimitered by whitespace.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Char">
            <summary>
            tokenizes into character sequence
            </summary>
        </member>
        <member name="T:Sentencepiece.NormalizerSpec">
            <summary>
            NormalizerSpec encodes a various parameters for string normalization
            </summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.Name">
            <summary>
            name of normalization rule.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasName">
            <summary>Gets whether the "name" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearName">
            <summary>Clears the value of the "name" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.PrecompiledCharsmapFieldNumber">
            <summary>Field number for the "precompiled_charsmap" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.PrecompiledCharsmap">
            <summary>
            Pre-compiled normalization rule created by
            Builder::GetPrecompiledCharsMap() or Builder::CompileCharsMap() method.
            Usually this field is set by Builder::GetNormalizerSpec() method.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasPrecompiledCharsmap">
            <summary>Gets whether the "precompiled_charsmap" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearPrecompiledCharsmap">
            <summary>Clears the value of the "precompiled_charsmap" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.AddDummyPrefixFieldNumber">
            <summary>Field number for the "add_dummy_prefix" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.AddDummyPrefix">
            <summary>
            Adds dummy whitespace at the beginning of text in order to
            treat "world" in "world" and "hello world" in the same way.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasAddDummyPrefix">
            <summary>Gets whether the "add_dummy_prefix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearAddDummyPrefix">
            <summary>Clears the value of the "add_dummy_prefix" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.RemoveExtraWhitespacesFieldNumber">
            <summary>Field number for the "remove_extra_whitespaces" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.RemoveExtraWhitespaces">
            <summary>
            Removes leading, trailing, and duplicate internal whitespace.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasRemoveExtraWhitespaces">
            <summary>Gets whether the "remove_extra_whitespaces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearRemoveExtraWhitespaces">
            <summary>Clears the value of the "remove_extra_whitespaces" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.EscapeWhitespacesFieldNumber">
            <summary>Field number for the "escape_whitespaces" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.EscapeWhitespaces">
            <summary>
            Replaces whitespace with meta symbol.
            This field must be true to train sentence piece model.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasEscapeWhitespaces">
            <summary>Gets whether the "escape_whitespaces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearEscapeWhitespaces">
            <summary>Clears the value of the "escape_whitespaces" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.NormalizationRuleTsvFieldNumber">
            <summary>Field number for the "normalization_rule_tsv" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.NormalizationRuleTsv">
            <summary>
            Custom normalization rule file in TSV format.
            https://github.com/google/sentencepiece/blob/master/doc/normalization.md
            This field is only used in SentencePieceTrainer::Train() method, which
            compiles the rule into the binary rule stored in `precompiled_charsmap`.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasNormalizationRuleTsv">
            <summary>Gets whether the "normalization_rule_tsv" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearNormalizationRuleTsv">
            <summary>Clears the value of the "normalization_rule_tsv" field</summary>
        </member>
        <member name="T:Sentencepiece.SelfTestData">
            <summary>
            Proto to store samples for self-testing.
            </summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.SamplesFieldNumber">
            <summary>Field number for the "samples" field.</summary>
        </member>
        <member name="T:Sentencepiece.SelfTestData.Types">
            <summary>Container for nested types declared in the SelfTestData message type.</summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.Types.Sample.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <member name="P:Sentencepiece.SelfTestData.Types.Sample.HasInput">
            <summary>Gets whether the "input" field is set</summary>
        </member>
        <member name="M:Sentencepiece.SelfTestData.Types.Sample.ClearInput">
            <summary>Clears the value of the "input" field</summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.Types.Sample.ExpectedFieldNumber">
            <summary>Field number for the "expected" field.</summary>
        </member>
        <member name="P:Sentencepiece.SelfTestData.Types.Sample.HasExpected">
            <summary>Gets whether the "expected" field is set</summary>
        </member>
        <member name="M:Sentencepiece.SelfTestData.Types.Sample.ClearExpected">
            <summary>Clears the value of the "expected" field</summary>
        </member>
        <member name="T:Sentencepiece.ModelProto">
            <summary>
            ModelProto stores model parameters.
            SentencePieceProcessor is supposed to be self-contained.
            All settings/parameters which may change the behavior must be encoded
            in ModelProto.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.PiecesFieldNumber">
            <summary>Field number for the "pieces" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Pieces">
            <summary>
            Sentence pieces with scores.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.TrainerSpecFieldNumber">
            <summary>Field number for the "trainer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.TrainerSpec">
            <summary>
            Spec used to generate this model file.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.NormalizerSpecFieldNumber">
            <summary>Field number for the "normalizer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.NormalizerSpec">
            <summary>
            Spec for text normalization.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.SelfTestDataFieldNumber">
            <summary>Field number for the "self_test_data" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.SelfTestData">
            <summary>
            Stores sample input and its expected segmentation to verify the model.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.DenormalizerSpecFieldNumber">
            <summary>Field number for the "denormalizer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.DenormalizerSpec">
            <summary>
            Spec for text de-normalization.
            </summary>
        </member>
        <member name="T:Sentencepiece.ModelProto.Types">
            <summary>Container for nested types declared in the ModelProto message type.</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.PieceFieldNumber">
            <summary>Field number for the "piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.Piece">
            <summary>
            piece must not be empty.
            </summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasPiece">
            <summary>Gets whether the "piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearPiece">
            <summary>Clears the value of the "piece" field</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasScore">
            <summary>Gets whether the "score" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearScore">
            <summary>Clears the value of the "score" field</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasType">
            <summary>Gets whether the "type" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearType">
            <summary>Clears the value of the "type" field</summary>
        </member>
        <member name="T:Sentencepiece.ModelProto.Types.SentencePiece.Types">
            <summary>Container for nested types declared in the SentencePiece message type.</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Normal">
            <summary>
            normal symbol
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Unknown">
            <summary>
            unknown symbol. only &lt;unk> for now.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Control">
            <summary>
            control symbols. &lt;/s>, &lt;s>, &lt;2ja> etc.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.UserDefined">
            <summary>
            user defined symbols.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Byte">
            <summary>
            Typical usage of USER_DEFINED symbol
            is placeholder.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Unused">
            <summary>
            this piece is not used.
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.GetPinnableReference">
            <summary>
            Get a pinnable reference to the builder.
            Does not ensure there is a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/>
            This overload is pattern matched in the C# 7.3+ compiler so you can omit
            the explicit method call, and write eg "fixed (char* c = builder)"
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.GetPinnableReference(System.Boolean)">
            <summary>
            Get a pinnable reference to the builder.
            </summary>
            <param name="terminate">Ensures that the builder has a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/></param>
        </member>
        <member name="P:System.Text.ValueStringBuilder.RawChars">
            <summary>Returns the underlying storage of the builder.</summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.AsSpan(System.Boolean)">
            <summary>
            Returns a span around the contents of the builder.
            </summary>
            <param name="terminate">Ensures that the builder has a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/></param>
        </member>
        <member name="M:System.Text.ValueStringBuilder.RemoveLastChar">
            <summary>
            Remove last character in the builder.
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.Grow(System.Int32)">
            <summary>
            Resize the internal buffer either by doubling current buffer size or
            by adding <paramref name="additionalCapacityBeyondPos"/> to
            <see cref="F:System.Text.ValueStringBuilder._pos"/> whichever is greater.
            </summary>
            <param name="additionalCapacityBeyondPos">
            Number of chars requested beyond current position.
            </param>
        </member>
    </members>
</doc>
